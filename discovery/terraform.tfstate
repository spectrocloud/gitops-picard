{
  "version": 4,
  "terraform_version": "0.14.3",
  "serial": 7,
  "lineage": "876a194f-d367-5fe5-2cf6-86a9fc81875e",
  "outputs": {},
  "resources": [
    {
      "mode": "data",
      "type": "spectrocloud_cloudaccount_vsphere",
      "name": "this",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "6011e1218102177b6b5aa9bd",
            "name": "demo"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "cni-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "aws",
              "gcp",
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c08697feca1",
            "name": "cni-calico",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "manifests:\n  calico:\n\n    # IPAM type to use. Supported types are calico-ipam, host-local\n    ipamType: \"host-local\"\n\n    # Uncomment property below when ipamType is set to calico-ipam\n    # networkCIDR to use (should match the kubernetes podCIDR)\n    #calicoNetworkCIDR: \"192.168.0.0/16\"\n\n    # Should be one of CALICO_IPV4POOL_IPIP or CALICO_IPV4POOL_VXLAN\n    encapsulationType: \"CALICO_IPV4POOL_IPIP\"\n\n    # Should be one of Always, CrossSubnet, Never\n    encapsulationMode: \"Always\"\n",
            "version": "3.16.0"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "csi-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c08ca138776",
            "name": "csi-vsphere-volume",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "manifests:\n  vsphere:\n\n    #DiskFormat types : thin, zeroedthick and eagerzeroedthick\n    diskformat: \"thin\"\n\n    #If specified, the volume will be created on the datastore specified in the storage class.\n    #This field is optional. If the datastore is not specified, then the volume will be created\n    # on the datastore specified in the vSphere config file used to initialize the vSphere Cloud Provider.\n    datastore: \"\"\n\n    #Toggle for Default class\n    isDefaultClass: \"true\"\n\n    #Supported binding modes are Immediate, WaitForFirstConsumer\n    volumeBindingMode: \"Immediate\"",
            "version": "1.0.0"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "hipster-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "aws",
              "azure",
              "gcp",
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c09662d7d5f",
            "name": "sapp-hipster",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "manifests:\n  hipster:\n    # Liveness probe default itmeout\n    timeout: 60\n\n    # Disable Tracing\n    disableTracing: true\n\n    # The namespace to create the app in\n    namespace: \"hipster-app\"\n\n",
            "version": "2.0.0"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "istio-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "aws",
              "azure",
              "gcp",
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c08f704634d",
            "name": "istio",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "charts:\n  istio-operator:\n    hub: docker.io/istio\n    tag: 1.6.2\n    operatorNamespace: istio-operator\n    istioNamespace: istio-system\n  istio-controlplane:\n    namespace: istio-system\n    controlPlaneName: istio-controlplane\n    ############################################ ISTIO PROFILES #################################################\n    # default: generally for production (istiod, prometheus, ingress gateway)\n    # demo: enable everything for production (istiod, prometheus, ingress gateway, egress, kiali, tracing)\n    # remote: remote cluster of a multicluster mesh, with a shared control plane\n    ############################################################################################################\n    spec:\n      profile: demo\n\n      # Disable Pod disruption budget for the additional components. Otherwise, pods will get stuck when node is drained\n      values:\n        global:\n          defaultPodDisruptionBudget:\n            enabled: false\n\n    ####### REMOTE PROFILE ########\n    # For REMOTE\n    # spec:\n    #   profile: remote\n    #   values:\n    #     global:\n    #       # The remote cluster's name and network name must match the values specified in the\n    #       # mesh network configuration of the main cluster.\n    #       multiCluster:\n    #         clusterName: ${REMOTE_CLUSTER_NAME}\n    #       network: ${REMOTE_CLUSTER_NETWORK}\n    #\n    #       # Replace ISTIOD_REMOTE_EP with the the value of ISTIOD_REMOTE_EP set earlier.\n    #       remotePilotAddress: ${ISTIOD_REMOTE_EP}\n    ####### END REMOTE PROFILE ########\n",
            "version": "1.6.2"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "k8s-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "aws",
              "azure",
              "gcp",
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c0915b07611",
            "name": "kubernetes",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "pack:\n  k8sHardening: True\n  #CIDR Range for Pods in cluster\n  # Note : This must not overlap with any of the host or service network\n  podCIDR: \"192.168.0.0/16\"\n  #CIDR notation IP range from which to assign service cluster IPs\n  # Note : This must not overlap with any IP ranges assigned to nodes for pods.\n  serviceClusterIpRange: \"10.96.0.0/12\"\n\n# KubeAdm customization for kubernetes hardening. Below config will be ignored if k8sHardening property above is disabled\nkubeadmconfig:\n  apiServer:\n    extraArgs:\n      anonymous-auth: \"true\"\n      insecure-port: \"0\"\n      profiling: \"false\"\n      disable-admission-plugins: \"AlwaysAdmit\"\n      default-not-ready-toleration-seconds: \"60\"\n      default-unreachable-toleration-seconds: \"60\"\n      enable-admission-plugins: \"AlwaysPullImages,NamespaceLifecycle,ServiceAccount,NodeRestriction,PodSecurityPolicy\"\n      audit-log-path: /var/log/apiserver/audit.log\n      audit-policy-file: /etc/kubernetes/audit-policy.yaml\n      audit-log-maxage: \"30\"\n      audit-log-maxbackup: \"10\"\n      audit-log-maxsize: \"100\"\n      authorization-mode: RBAC,Node\n      tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n    extraVolumes:\n      - name: audit-log\n        hostPath: /var/log/apiserver\n        mountPath: /var/log/apiserver\n        pathType: DirectoryOrCreate\n      - name: audit-policy\n        hostPath: /etc/kubernetes/audit-policy.yaml\n        mountPath: /etc/kubernetes/audit-policy.yaml\n        readOnly: true\n        pathType: File\n  controllerManager:\n    extraArgs:\n      profiling: \"false\"\n      terminated-pod-gc-threshold: \"25\"\n      pod-eviction-timeout: \"1m0s\"\n      use-service-account-credentials: \"true\"\n      feature-gates: \"RotateKubeletServerCertificate=true\"\n      address: \"0.0.0.0\"\n  scheduler:\n    extraArgs:\n      profiling: \"false\"\n      address: \"0.0.0.0\"\n  kubeletExtraArgs:\n    read-only-port : \"0\"\n    event-qps: \"0\"\n    feature-gates: \"RotateKubeletServerCertificate=true\"\n    protect-kernel-defaults: \"true\"\n    tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n  files:\n    - path: hardening/audit-policy.yaml\n      targetPath: /etc/kubernetes/audit-policy.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/privileged-psp.yaml\n      targetPath: /etc/kubernetes/hardening/privileged-psp.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/90-kubelet.conf\n      targetPath: /etc/sysctl.d/90-kubelet.conf\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n  preKubeadmCommands:\n    # For enabling 'protect-kernel-defaults' flag to kubelet, kernel parameters changes are required\n    - 'echo \"====\u003e Applying kernel parameters for Kubelet\"'\n    - 'sysctl -p /etc/sysctl.d/90-kubelet.conf'\n  postKubeadmCommands:\n    # Apply the privileged PodSecurityPolicy on the first master node ; Otherwise, CNI (and other) pods won't come up\n    - 'export KUBECONFIG=/etc/kubernetes/admin.conf'\n    # Sometimes api server takes a little longer to respond. Retry if applying the pod-security-policy manifest fails\n    - '[ -f \"$KUBECONFIG\" ] \u0026\u0026 { echo \" ====\u003e Applying PodSecurityPolicy\" ; until $(kubectl apply -f /etc/kubernetes/hardening/privileged-psp.yaml \u003e /dev/null ); do echo \"Failed to apply PodSecurityPolicies, will retry in 5s\" ; sleep 5 ; done ; } || echo \"Skipping PodSecurityPolicy for worker nodes\"'",
            "version": "1.18.13"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "lbmetal-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c09408ed39e",
            "name": "lb-metallb",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "manifests:\n  metallb:\n\n    #The namespace to use for deploying MetalLB\n    namespace: \"metallb-system\"\n\n    #MetalLB will skip setting .0 \u0026 .255 IP address when this flag is enabled\n    avoidBuggyIps: true\n\n    # Layer 2 config; The IP address range MetalLB should use while assigning IP's for svc type LoadBalancer\n    # For the supported formats, check https://metallb.universe.tf/configuration/#layer-2-configuration\n    addresses:\n    - 10.10.184.0-10.10.184.255\n\n",
            "version": "0.8.3"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "nginx-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "aws",
              "azure",
              "gcp",
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c094cde692e",
            "name": "nginx",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "pack:\n  #The namespace (on the target cluster) to install this chart\n  #When not found, a new namespace will be created\n  namespace: \"nginx\"\n\ncharts:\n  nginx-ingress:\n    fullnameOverride: \"nginx-ingress\"\n    controller:\n      fullnameOverride: nginx-ingress.controller\n      name: controller\n      image:\n        repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n        tag: \"0.26.1\"\n        pullPolicy: IfNotPresent\n        # www-data -\u003e uid 33\n        runAsUser: 33\n        allowPrivilegeEscalation: true\n\n      # Configures the ports the nginx-controller listens on\n      containerPort:\n        http: 80\n        https: 443\n\n      # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/\n      config: {}\n\n      # Will add custom headers before sending traffic to backends according to https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers\n      proxySetHeaders: {}\n\n      # Will add custom headers before sending response traffic to the client according to: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#add-headers\n      addHeaders: {}\n\n      # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),\n      # since CNI and hostport don't mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920\n      # is merged\n      hostNetwork: false\n\n      # Optionally change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.\n      # By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller\n      # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.\n      dnsPolicy: ClusterFirst\n\n      # Bare-metal considerations via the host network https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#via-the-host-network\n      # Ingress status was blank because there is no Service exposing the NGINX Ingress controller in a configuration using the host network, the default --publish-service flag used in standard cloud setups does not apply\n      reportNodeInternalIp: false\n\n      ## Use host ports 80 and 443\n      daemonset:\n        useHostPort: false\n\n        hostPorts:\n          http: 80\n          https: 443\n\n      ## Required only if defaultBackend.enabled = false\n      ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n      ##\n      defaultBackendService: \"\"\n\n      ## Election ID to use for status update\n      ##\n      electionID: ingress-controller-leader\n\n      ## Name of the ingress class to route through this controller\n      ##\n      ingressClass: nginx\n\n      # labels to add to the pod container metadata\n      podLabels: {}\n      #  key: value\n\n      ## Security Context policies for controller pods\n      ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n      ## notes on enabling and using sysctls\n      ##\n      podSecurityContext: {}\n\n      ## Allows customization of the external service\n      ## the ingress will be bound to via DNS\n      publishService:\n        enabled: true\n        ## Allows overriding of the publish service to bind to\n        ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n        ##\n        pathOverride: \"\"\n\n      ## Limit the scope of the controller\n      ##\n      scope:\n        enabled: false\n        namespace: \"\"   # defaults to .Release.Namespace\n\n      ## Allows customization of the configmap / nginx-configmap namespace\n      ##\n      configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n      ## Allows customization of the tcp-services-configmap namespace\n      ##\n      tcp:\n        configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n      ## Allows customization of the udp-services-configmap namespace\n      ##\n      udp:\n        configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n      ## Additional command line arguments to pass to nginx-ingress-controller\n      ## E.g. to specify the default SSL certificate you can use\n      ## extraArgs:\n      ##   default-ssl-certificate: \"\u003cnamespace\u003e/\u003csecret_name\u003e\"\n      extraArgs: {}\n\n      ## Additional environment variables to set\n      extraEnvs: []\n      # extraEnvs:\n      #   - name: FOO\n      #     valueFrom:\n      #       secretKeyRef:\n      #         key: FOO\n      #         name: secret-resource\n\n      ## DaemonSet or Deployment\n      ##\n      kind: Deployment\n\n      ## Annotations to be added to the controller deployment\n      ##\n      deploymentAnnotations: {}\n\n      # The update strategy to apply to the Deployment or DaemonSet\n      ##\n      updateStrategy: {}\n      #  rollingUpdate:\n      #    maxUnavailable: 1\n      #  type: RollingUpdate\n\n      # minReadySeconds to avoid killing pods before we are ready\n      ##\n      minReadySeconds: 0\n\n\n      ## Node tolerations for server scheduling to nodes with taints\n      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n      ##\n      tolerations: []\n      #  - key: \"key\"\n      #    operator: \"Equal|Exists\"\n      #    value: \"value\"\n      #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n      ## Affinity and anti-affinity\n      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n      ##\n      affinity: {}\n        # # An example of preferred pod anti-affinity, weight is in the range 1-100\n        # podAntiAffinity:\n        #   preferredDuringSchedulingIgnoredDuringExecution:\n        #   - weight: 100\n        #     podAffinityTerm:\n        #       labelSelector:\n        #         matchExpressions:\n        #         - key: app\n        #           operator: In\n        #           values:\n        #           - nginx-ingress\n        #       topologyKey: kubernetes.io/hostname\n\n        # # An example of required pod anti-affinity\n        # podAntiAffinity:\n        #   requiredDuringSchedulingIgnoredDuringExecution:\n        #   - labelSelector:\n        #       matchExpressions:\n        #       - key: app\n        #         operator: In\n        #         values:\n      #         - nginx-ingress\n      #     topologyKey: \"kubernetes.io/hostname\"\n\n      ## terminationGracePeriodSeconds\n      ##\n      terminationGracePeriodSeconds: 60\n\n      ## Node labels for controller pod assignment\n      ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n      ##\n      nodeSelector: {}\n\n      ## Liveness and readiness probe values\n      ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n      ##\n      livenessProbe:\n        failureThreshold: 3\n        initialDelaySeconds: 10\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 1\n        port: 10254\n      readinessProbe:\n        failureThreshold: 3\n        initialDelaySeconds: 10\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 1\n        port: 10254\n\n      ## Annotations to be added to controller pods\n      ##\n      podAnnotations: {}\n\n      replicaCount: 1\n\n      minAvailable: 1\n\n      resources:\n        limits:\n          cpu: 500m\n          memory: 500Mi\n        requests:\n          cpu: 100m\n          memory: 64Mi\n\n      autoscaling:\n        enabled: true\n        minReplicas: 1\n        maxReplicas: 3\n        targetCPUUtilizationPercentage: 70\n        targetMemoryUtilizationPercentage: 80\n\n      ## Override NGINX template\n      customTemplate:\n        configMapName: \"\"\n        configMapKey: \"\"\n\n      service:\n        enabled: true\n\n        annotations: {}\n        labels: {}\n        ## Deprecated, instead simply do not provide a clusterIP value\n        omitClusterIP: false\n        # clusterIP: \"\"\n\n        ## List of IP addresses at which the controller services are available\n        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n        ##\n        externalIPs: []\n\n        loadBalancerIP: \"\"\n        loadBalancerSourceRanges: []\n\n        enableHttp: true\n        enableHttps: true\n\n        ## Set external traffic policy to: \"Local\" to preserve source IP on\n        ## providers supporting it\n        ## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer\n        externalTrafficPolicy: \"\"\n\n        healthCheckNodePort: 0\n\n        ports:\n          http: 80\n          https: 443\n\n        targetPorts:\n          http: http\n          https: https\n\n        type: LoadBalancer\n\n        # type: NodePort\n        # nodePorts:\n        #   http: 32080\n        #   https: 32443\n        #   tcp:\n        #     8080: 32808\n        nodePorts:\n          http: \"\"\n          https: \"\"\n          tcp: {}\n          udp: {}\n\n      extraContainers: []\n      ## Additional containers to be added to the controller pod.\n      ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n      #  - name: my-sidecar\n      #    image: nginx:latest\n      #  - name: lemonldap-ng-controller\n      #    image: lemonldapng/lemonldap-ng-controller:0.2.0\n      #    args:\n      #      - /lemonldap-ng-controller\n      #      - --alsologtostderr\n      #      - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n      #    env:\n      #      - name: POD_NAME\n      #        valueFrom:\n      #          fieldRef:\n      #            fieldPath: metadata.name\n      #      - name: POD_NAMESPACE\n      #        valueFrom:\n      #          fieldRef:\n      #            fieldPath: metadata.namespace\n      #    volumeMounts:\n      #    - name: copy-portal-skins\n      #      mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n      extraVolumeMounts: []\n      ## Additional volumeMounts to the controller main container.\n      #  - name: copy-portal-skins\n      #   mountPath: /var/lib/lemonldap-ng/portal/skins\n\n      extraVolumes: []\n      ## Additional volumes to the controller pod.\n      #  - name: copy-portal-skins\n      #    emptyDir: {}\n\n      extraInitContainers: []\n      ## Containers, which are run before the app containers are started.\n      # - name: init-myservice\n      #   image: busybox\n      #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']\n\n      admissionWebhooks:\n        enabled: false\n        failurePolicy: Fail\n        port: 8443\n\n        service:\n          annotations: {}\n          ## Deprecated, instead simply do not provide a clusterIP value\n          omitClusterIP: false\n          # clusterIP: \"\"\n          externalIPs: []\n          loadBalancerIP: \"\"\n          loadBalancerSourceRanges: []\n          servicePort: 443\n          type: ClusterIP\n\n        patch:\n          enabled: true\n          image:\n            repository: jettech/kube-webhook-certgen\n            tag: v1.0.0\n            pullPolicy: IfNotPresent\n          ## Provide a priority class name to the webhook patching job\n          ##\n          priorityClassName: \"\"\n          podAnnotations: {}\n          nodeSelector: {}\n\n      metrics:\n        port: 10254\n        # if this port is changed, change healthz-port: in extraArgs: accordingly\n        enabled: true\n\n        service:\n          annotations: {}\n          # prometheus.io/scrape: \"true\"\n          # prometheus.io/port: \"10254\"\n\n          ## Deprecated, instead simply do not provide a clusterIP value\n          omitClusterIP: false\n          # clusterIP: \"\"\n\n          ## List of IP addresses at which the stats-exporter service is available\n          ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n          ##\n          externalIPs: []\n\n          loadBalancerIP: \"\"\n          loadBalancerSourceRanges: []\n          servicePort: 9913\n          type: ClusterIP\n\n        serviceMonitor:\n          enabled: false\n          additionalLabels: {}\n          namespace: \"\"\n          namespaceSelector: {}\n          # Default: scrape .Release.Namespace only\n          # To scrape all, use the following:\n          # namespaceSelector:\n          #   any: true\n          scrapeInterval: 30s\n          # honorLabels: true\n\n        prometheusRule:\n          enabled: false\n          additionalLabels: {}\n          namespace: \"\"\n          rules: []\n            # # These are just examples rules, please adapt them to your needs\n            # - alert: TooMany500s\n            #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"5.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n            #   for: 1m\n            #   labels:\n            #     severity: critical\n            #   annotations:\n            #     description: Too many 5XXs\n            #     summary: More than 5% of the all requests did return 5XX, this require your attention\n            # - alert: TooMany400s\n            #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"4.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n            #   for: 1m\n            #   labels:\n            #     severity: critical\n            #   annotations:\n          #     description: Too many 4XXs\n          #     summary: More than 5% of the all requests did return 4XX, this require your attention\n\n\n      lifecycle: {}\n\n      priorityClassName: \"\"\n\n    ## Rollback limit\n    ##\n    revisionHistoryLimit: 10\n\n    ## Default 404 backend\n    ##\n    defaultBackend:\n\n      ## If false, controller.defaultBackendService must be provided\n      ##\n      enabled: true\n\n      name: default-backend\n      image:\n        repository: k8s.gcr.io/defaultbackend-amd64\n        tag: \"1.5\"\n        pullPolicy: IfNotPresent\n        # nobody user -\u003e uid 65534\n        runAsUser: 65534\n\n      extraArgs: {}\n\n      serviceAccount:\n        create: true\n        name:\n      ## Additional environment variables to set for defaultBackend pods\n      extraEnvs: []\n\n      port: 8080\n\n      ## Readiness and liveness probes for default backend\n      ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n      ##\n      livenessProbe:\n        failureThreshold: 3\n        initialDelaySeconds: 30\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 5\n      readinessProbe:\n        failureThreshold: 6\n        initialDelaySeconds: 0\n        periodSeconds: 5\n        successThreshold: 1\n        timeoutSeconds: 5\n\n      ## Node tolerations for server scheduling to nodes with taints\n      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n      ##\n      tolerations: []\n      #  - key: \"key\"\n      #    operator: \"Equal|Exists\"\n      #    value: \"value\"\n      #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n      affinity: {}\n\n      ## Security Context policies for controller pods\n      ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n      ## notes on enabling and using sysctls\n      ##\n      podSecurityContext: {}\n\n      # labels to add to the pod container metadata\n      podLabels: {}\n      #  key: value\n\n      ## Node labels for default backend pod assignment\n      ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n      ##\n      nodeSelector: {}\n\n      ## Annotations to be added to default backend pods\n      ##\n      podAnnotations: {}\n\n      replicaCount: 1\n\n      minAvailable: 1\n\n      resources:\n        limits:\n          cpu: 300m\n          memory: 400Mi\n        requests:\n          cpu: 10m\n          memory: 20Mi\n\n      service:\n        annotations: {}\n        ## Deprecated, instead simply do not provide a clusterIP value\n        omitClusterIP: false\n        # clusterIP: \"\"\n\n        ## List of IP addresses at which the default backend service is available\n        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n        ##\n        externalIPs: []\n\n        loadBalancerIP: \"\"\n        loadBalancerSourceRanges: []\n        servicePort: 80\n        type: ClusterIP\n\n      priorityClassName: \"\"\n\n    ## Enable RBAC as per https://github.com/kubernetes/ingress/tree/master/examples/rbac/nginx and https://github.com/kubernetes/ingress/issues/266\n    rbac:\n      create: true\n\n    # If true, create \u0026 use Pod Security Policy resources\n    # https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n    podSecurityPolicy:\n      enabled: false\n\n    serviceAccount:\n      create: true\n      name:\n\n    ## Optional array of imagePullSecrets containing private registry credentials\n    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    imagePullSecrets: []\n    # - name: secretName\n\n    # TCP service key:value pairs\n    # Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/tcp\n    ##\n    tcp: {}\n    #  8080: \"default/example-tcp-svc:9000\"\n\n    # UDP service key:value pairs\n    # Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/udp\n    ##\n    udp: {}\n    #  53: \"kube-system/kube-dns:53\"\n",
            "version": "0.26.1"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "data",
      "type": "spectrocloud_pack",
      "name": "ubuntu-vsphere",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": [
              "vsphere"
            ],
            "filters": null,
            "id": "6007ce6c861f9c09b0f28da4",
            "name": "ubuntu-vsphere",
            "registry_uid": "6007ce5c861f9c083d087acb",
            "values": "\n# Spectro Golden images includes most of the hardening standards recommended by CIS benchmarking v1.5\n\n# Uncomment below section to\n# 1. Include custom files to be copied over to the nodes and/or\n# 2. Execute list of commands before or after kubeadm init/join is executed\n#\n#kubeadmconfig:\n#  preKubeadmCommands:\n#  - echo \"Executing pre kube admin config commands\"\n#  - update-ca-certificates\n#  - 'systemctl restart containerd; sleep 3'\n#  - 'while [ ! -S /var/run/containerd/containerd.sock ]; do echo \"Waiting for containerd...\"; sleep 1; done'\n#  postKubeadmCommands:\n#  - echo \"Executing post kube admin config commands\"\n#  files:\n#  - targetPath: /usr/local/share/ca-certificates/mycom.crt\n#    targetOwner: \"root:root\"\n#    targetPermissions: \"0644\"\n#    content: |\n#      -----BEGIN CERTIFICATE-----\n#      MIICyzCCAbOgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl\n#      cm5ldGVzMB4XDTIwMDkyMjIzNDMyM1oXDTMwMDkyMDIzNDgyM1owFTETMBEGA1UE\n#      AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMdA\n#      nZYs1el/6f9PgV/aO9mzy7MvqaZoFnqO7Qi4LZfYzixLYmMUzi+h8/RLPFIoYLiz\n#      qiDn+P8c9I1uxB6UqGrBt7dkXfjrUZPs0JXEOX9U/6GFXL5C+n3AUlAxNCS5jobN\n#      fbLt7DH3WoT6tLcQefTta2K+9S7zJKcIgLmBlPNDijwcQsbenSwDSlSLkGz8v6N2\n#      7SEYNCV542lbYwn42kbcEq2pzzAaCqa5uEPsR9y+uzUiJpv5tDHUdjbFT8tme3vL\n#      9EdCPODkqtMJtCvz0hqd5SxkfeC2L+ypaiHIxbwbWe7GtliROvz9bClIeGY7gFBK\n#      jZqpLdbBVjo0NZBTJFUCAwEAAaMmMCQwDgYDVR0PAQH/BAQDAgKkMBIGA1UdEwEB\n#      /wQIMAYBAf8CAQAwDQYJKoZIhvcNAQELBQADggEBADIKoE0P+aVJGV9LWGLiOhki\n#      HFv/vPPAQ2MPk02rLjWzCaNrXD7aPPgT/1uDMYMHD36u8rYyf4qPtB8S5REWBM/Y\n#      g8uhnpa/tGsaqO8LOFj6zsInKrsXSbE6YMY6+A8qvv5lPWpJfrcCVEo2zOj7WGoJ\n#      ixi4B3fFNI+wih8/+p4xW+n3fvgqVYHJ3zo8aRLXbXwztp00lXurXUyR8EZxyR+6\n#      b+IDLmHPEGsY9KOZ9VLLPcPhx5FR9njFyXvDKmjUMJJgUpRkmsuU1mCFC+OHhj56\n#      IkLaSJf6z/p2a3YjTxvHNCqFMLbJ2FvJwYCRzsoT2wm2oulnUAMWPI10vdVM+Nc=\n#      -----END CERTIFICATE-----",
            "version": "18.04"
          },
          "sensitive_attributes": []
        }
      ]
    },
    {
      "mode": "managed",
      "type": "spectrocloud_cluster_profile",
      "name": "devvmware",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": "vsphere",
            "description": "basic cp",
            "id": "6011e056c6fdecdfd8d25af5",
            "name": "DevVMware",
            "pack": [
              {
                "name": "nginx",
                "tag": "0.26.x",
                "uid": "6007ce6c861f9c094cde692e",
                "values": "pack:\n  #The namespace (on the target cluster) to install this chart\n  #When not found, a new namespace will be created\n  namespace: \"nginx\"\n\ncharts:\n  nginx-ingress:\n    fullnameOverride: \"nginx-ingress\"\n    controller:\n      fullnameOverride: nginx-ingress.controller\n      name: controller\n      image:\n        repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n        tag: \"0.26.1\"\n        pullPolicy: IfNotPresent\n        # www-data -\u003e uid 33\n        runAsUser: 33\n        allowPrivilegeEscalation: true\n\n      # Configures the ports the nginx-controller listens on\n      containerPort:\n        http: 80\n        https: 443\n\n      # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/\n      config: {}\n\n      # Will add custom headers before sending traffic to backends according to https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers\n      proxySetHeaders: {}\n\n      # Will add custom headers before sending response traffic to the client according to: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#add-headers\n      addHeaders: {}\n\n      # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),\n      # since CNI and hostport don't mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920\n      # is merged\n      hostNetwork: false\n\n      # Optionally change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.\n      # By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller\n      # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.\n      dnsPolicy: ClusterFirst\n\n      # Bare-metal considerations via the host network https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#via-the-host-network\n      # Ingress status was blank because there is no Service exposing the NGINX Ingress controller in a configuration using the host network, the default --publish-service flag used in standard cloud setups does not apply\n      reportNodeInternalIp: false\n\n      ## Use host ports 80 and 443\n      daemonset:\n        useHostPort: false\n\n        hostPorts:\n          http: 80\n          https: 443\n\n      ## Required only if defaultBackend.enabled = false\n      ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n      ##\n      defaultBackendService: \"\"\n\n      ## Election ID to use for status update\n      ##\n      electionID: ingress-controller-leader\n\n      ## Name of the ingress class to route through this controller\n      ##\n      ingressClass: nginx\n\n      # labels to add to the pod container metadata\n      podLabels: {}\n      #  key: value\n\n      ## Security Context policies for controller pods\n      ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n      ## notes on enabling and using sysctls\n      ##\n      podSecurityContext: {}\n\n      ## Allows customization of the external service\n      ## the ingress will be bound to via DNS\n      publishService:\n        enabled: true\n        ## Allows overriding of the publish service to bind to\n        ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n        ##\n        pathOverride: \"\"\n\n      ## Limit the scope of the controller\n      ##\n      scope:\n        enabled: false\n        namespace: \"\"   # defaults to .Release.Namespace\n\n      ## Allows customization of the configmap / nginx-configmap namespace\n      ##\n      configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n      ## Allows customization of the tcp-services-configmap namespace\n      ##\n      tcp:\n        configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n      ## Allows customization of the udp-services-configmap namespace\n      ##\n      udp:\n        configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n      ## Additional command line arguments to pass to nginx-ingress-controller\n      ## E.g. to specify the default SSL certificate you can use\n      ## extraArgs:\n      ##   default-ssl-certificate: \"\u003cnamespace\u003e/\u003csecret_name\u003e\"\n      extraArgs: {}\n\n      ## Additional environment variables to set\n      extraEnvs: []\n      # extraEnvs:\n      #   - name: FOO\n      #     valueFrom:\n      #       secretKeyRef:\n      #         key: FOO\n      #         name: secret-resource\n\n      ## DaemonSet or Deployment\n      ##\n      kind: Deployment\n\n      ## Annotations to be added to the controller deployment\n      ##\n      deploymentAnnotations: {}\n\n      # The update strategy to apply to the Deployment or DaemonSet\n      ##\n      updateStrategy: {}\n      #  rollingUpdate:\n      #    maxUnavailable: 1\n      #  type: RollingUpdate\n\n      # minReadySeconds to avoid killing pods before we are ready\n      ##\n      minReadySeconds: 0\n\n\n      ## Node tolerations for server scheduling to nodes with taints\n      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n      ##\n      tolerations: []\n      #  - key: \"key\"\n      #    operator: \"Equal|Exists\"\n      #    value: \"value\"\n      #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n      ## Affinity and anti-affinity\n      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n      ##\n      affinity: {}\n        # # An example of preferred pod anti-affinity, weight is in the range 1-100\n        # podAntiAffinity:\n        #   preferredDuringSchedulingIgnoredDuringExecution:\n        #   - weight: 100\n        #     podAffinityTerm:\n        #       labelSelector:\n        #         matchExpressions:\n        #         - key: app\n        #           operator: In\n        #           values:\n        #           - nginx-ingress\n        #       topologyKey: kubernetes.io/hostname\n\n        # # An example of required pod anti-affinity\n        # podAntiAffinity:\n        #   requiredDuringSchedulingIgnoredDuringExecution:\n        #   - labelSelector:\n        #       matchExpressions:\n        #       - key: app\n        #         operator: In\n        #         values:\n      #         - nginx-ingress\n      #     topologyKey: \"kubernetes.io/hostname\"\n\n      ## terminationGracePeriodSeconds\n      ##\n      terminationGracePeriodSeconds: 60\n\n      ## Node labels for controller pod assignment\n      ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n      ##\n      nodeSelector: {}\n\n      ## Liveness and readiness probe values\n      ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n      ##\n      livenessProbe:\n        failureThreshold: 3\n        initialDelaySeconds: 10\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 1\n        port: 10254\n      readinessProbe:\n        failureThreshold: 3\n        initialDelaySeconds: 10\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 1\n        port: 10254\n\n      ## Annotations to be added to controller pods\n      ##\n      podAnnotations: {}\n\n      replicaCount: 1\n\n      minAvailable: 1\n\n      resources:\n        limits:\n          cpu: 500m\n          memory: 500Mi\n        requests:\n          cpu: 100m\n          memory: 64Mi\n\n      autoscaling:\n        enabled: true\n        minReplicas: 1\n        maxReplicas: 3\n        targetCPUUtilizationPercentage: 70\n        targetMemoryUtilizationPercentage: 80\n\n      ## Override NGINX template\n      customTemplate:\n        configMapName: \"\"\n        configMapKey: \"\"\n\n      service:\n        enabled: true\n\n        annotations: {}\n        labels: {}\n        ## Deprecated, instead simply do not provide a clusterIP value\n        omitClusterIP: false\n        # clusterIP: \"\"\n\n        ## List of IP addresses at which the controller services are available\n        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n        ##\n        externalIPs: []\n\n        loadBalancerIP: \"\"\n        loadBalancerSourceRanges: []\n\n        enableHttp: true\n        enableHttps: true\n\n        ## Set external traffic policy to: \"Local\" to preserve source IP on\n        ## providers supporting it\n        ## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer\n        externalTrafficPolicy: \"\"\n\n        healthCheckNodePort: 0\n\n        ports:\n          http: 80\n          https: 443\n\n        targetPorts:\n          http: http\n          https: https\n\n        type: LoadBalancer\n\n        # type: NodePort\n        # nodePorts:\n        #   http: 32080\n        #   https: 32443\n        #   tcp:\n        #     8080: 32808\n        nodePorts:\n          http: \"\"\n          https: \"\"\n          tcp: {}\n          udp: {}\n\n      extraContainers: []\n      ## Additional containers to be added to the controller pod.\n      ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n      #  - name: my-sidecar\n      #    image: nginx:latest\n      #  - name: lemonldap-ng-controller\n      #    image: lemonldapng/lemonldap-ng-controller:0.2.0\n      #    args:\n      #      - /lemonldap-ng-controller\n      #      - --alsologtostderr\n      #      - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n      #    env:\n      #      - name: POD_NAME\n      #        valueFrom:\n      #          fieldRef:\n      #            fieldPath: metadata.name\n      #      - name: POD_NAMESPACE\n      #        valueFrom:\n      #          fieldRef:\n      #            fieldPath: metadata.namespace\n      #    volumeMounts:\n      #    - name: copy-portal-skins\n      #      mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n      extraVolumeMounts: []\n      ## Additional volumeMounts to the controller main container.\n      #  - name: copy-portal-skins\n      #   mountPath: /var/lib/lemonldap-ng/portal/skins\n\n      extraVolumes: []\n      ## Additional volumes to the controller pod.\n      #  - name: copy-portal-skins\n      #    emptyDir: {}\n\n      extraInitContainers: []\n      ## Containers, which are run before the app containers are started.\n      # - name: init-myservice\n      #   image: busybox\n      #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']\n\n      admissionWebhooks:\n        enabled: false\n        failurePolicy: Fail\n        port: 8443\n\n        service:\n          annotations: {}\n          ## Deprecated, instead simply do not provide a clusterIP value\n          omitClusterIP: false\n          # clusterIP: \"\"\n          externalIPs: []\n          loadBalancerIP: \"\"\n          loadBalancerSourceRanges: []\n          servicePort: 443\n          type: ClusterIP\n\n        patch:\n          enabled: true\n          image:\n            repository: jettech/kube-webhook-certgen\n            tag: v1.0.0\n            pullPolicy: IfNotPresent\n          ## Provide a priority class name to the webhook patching job\n          ##\n          priorityClassName: \"\"\n          podAnnotations: {}\n          nodeSelector: {}\n\n      metrics:\n        port: 10254\n        # if this port is changed, change healthz-port: in extraArgs: accordingly\n        enabled: true\n\n        service:\n          annotations: {}\n          # prometheus.io/scrape: \"true\"\n          # prometheus.io/port: \"10254\"\n\n          ## Deprecated, instead simply do not provide a clusterIP value\n          omitClusterIP: false\n          # clusterIP: \"\"\n\n          ## List of IP addresses at which the stats-exporter service is available\n          ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n          ##\n          externalIPs: []\n\n          loadBalancerIP: \"\"\n          loadBalancerSourceRanges: []\n          servicePort: 9913\n          type: ClusterIP\n\n        serviceMonitor:\n          enabled: false\n          additionalLabels: {}\n          namespace: \"\"\n          namespaceSelector: {}\n          # Default: scrape .Release.Namespace only\n          # To scrape all, use the following:\n          # namespaceSelector:\n          #   any: true\n          scrapeInterval: 30s\n          # honorLabels: true\n\n        prometheusRule:\n          enabled: false\n          additionalLabels: {}\n          namespace: \"\"\n          rules: []\n            # # These are just examples rules, please adapt them to your needs\n            # - alert: TooMany500s\n            #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"5.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n            #   for: 1m\n            #   labels:\n            #     severity: critical\n            #   annotations:\n            #     description: Too many 5XXs\n            #     summary: More than 5% of the all requests did return 5XX, this require your attention\n            # - alert: TooMany400s\n            #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"4.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n            #   for: 1m\n            #   labels:\n            #     severity: critical\n            #   annotations:\n          #     description: Too many 4XXs\n          #     summary: More than 5% of the all requests did return 4XX, this require your attention\n\n\n      lifecycle: {}\n\n      priorityClassName: \"\"\n\n    ## Rollback limit\n    ##\n    revisionHistoryLimit: 10\n\n    ## Default 404 backend\n    ##\n    defaultBackend:\n\n      ## If false, controller.defaultBackendService must be provided\n      ##\n      enabled: true\n\n      name: default-backend\n      image:\n        repository: k8s.gcr.io/defaultbackend-amd64\n        tag: \"1.5\"\n        pullPolicy: IfNotPresent\n        # nobody user -\u003e uid 65534\n        runAsUser: 65534\n\n      extraArgs: {}\n\n      serviceAccount:\n        create: true\n        name:\n      ## Additional environment variables to set for defaultBackend pods\n      extraEnvs: []\n\n      port: 8080\n\n      ## Readiness and liveness probes for default backend\n      ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n      ##\n      livenessProbe:\n        failureThreshold: 3\n        initialDelaySeconds: 30\n        periodSeconds: 10\n        successThreshold: 1\n        timeoutSeconds: 5\n      readinessProbe:\n        failureThreshold: 6\n        initialDelaySeconds: 0\n        periodSeconds: 5\n        successThreshold: 1\n        timeoutSeconds: 5\n\n      ## Node tolerations for server scheduling to nodes with taints\n      ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n      ##\n      tolerations: []\n      #  - key: \"key\"\n      #    operator: \"Equal|Exists\"\n      #    value: \"value\"\n      #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n      affinity: {}\n\n      ## Security Context policies for controller pods\n      ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n      ## notes on enabling and using sysctls\n      ##\n      podSecurityContext: {}\n\n      # labels to add to the pod container metadata\n      podLabels: {}\n      #  key: value\n\n      ## Node labels for default backend pod assignment\n      ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n      ##\n      nodeSelector: {}\n\n      ## Annotations to be added to default backend pods\n      ##\n      podAnnotations: {}\n\n      replicaCount: 1\n\n      minAvailable: 1\n\n      resources:\n        limits:\n          cpu: 300m\n          memory: 400Mi\n        requests:\n          cpu: 10m\n          memory: 20Mi\n\n      service:\n        annotations: {}\n        ## Deprecated, instead simply do not provide a clusterIP value\n        omitClusterIP: false\n        # clusterIP: \"\"\n\n        ## List of IP addresses at which the default backend service is available\n        ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n        ##\n        externalIPs: []\n\n        loadBalancerIP: \"\"\n        loadBalancerSourceRanges: []\n        servicePort: 80\n        type: ClusterIP\n\n      priorityClassName: \"\"\n\n    ## Enable RBAC as per https://github.com/kubernetes/ingress/tree/master/examples/rbac/nginx and https://github.com/kubernetes/ingress/issues/266\n    rbac:\n      create: true\n\n    # If true, create \u0026 use Pod Security Policy resources\n    # https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n    podSecurityPolicy:\n      enabled: false\n\n    serviceAccount:\n      create: true\n      name:\n\n    ## Optional array of imagePullSecrets containing private registry credentials\n    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    imagePullSecrets: []\n    # - name: secretName\n\n    # TCP service key:value pairs\n    # Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/tcp\n    ##\n    tcp: {}\n    #  8080: \"default/example-tcp-svc:9000\"\n\n    # UDP service key:value pairs\n    # Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/udp\n    ##\n    udp: {}\n    #  53: \"kube-system/kube-dns:53\"\n"
              },
              {
                "name": "lb-metallb",
                "tag": "0.8.x",
                "uid": "6007ce6c861f9c09408ed39e",
                "values": "manifests:\n  metallb:\n\n    #The namespace to use for deploying MetalLB\n    namespace: \"metallb-system\"\n\n    #MetalLB will skip setting .0 \u0026 .255 IP address when this flag is enabled\n    avoidBuggyIps: true\n\n    # Layer 2 config; The IP address range MetalLB should use while assigning IP's for svc type LoadBalancer\n    # For the supported formats, check https://metallb.universe.tf/configuration/#layer-2-configuration\n    addresses:\n    - 10.10.182.0-10.10.182.9\n"
              },
              {
                "name": "csi-vsphere-volume",
                "tag": "1.0.x",
                "uid": "6007ce6c861f9c08ca138776",
                "values": "manifests:\n  vsphere:\n\n    #DiskFormat types : thin, zeroedthick and eagerzeroedthick\n    diskformat: \"thin\"\n\n    #If specified, the volume will be created on the datastore specified in the storage class.\n    #This field is optional. If the datastore is not specified, then the volume will be created\n    # on the datastore specified in the vSphere config file used to initialize the vSphere Cloud Provider.\n    datastore: \"\"\n\n    #Toggle for Default class\n    isDefaultClass: \"true\"\n\n    #Supported binding modes are Immediate, WaitForFirstConsumer\n    volumeBindingMode: \"Immediate\""
              },
              {
                "name": "cni-calico",
                "tag": "3.16.x",
                "uid": "6007ce6c861f9c08697feca1",
                "values": "manifests:\n  calico:\n\n    # IPAM type to use. Supported types are calico-ipam, host-local\n    ipamType: \"host-local\"\n\n    # Uncomment property below when ipamType is set to calico-ipam\n    # networkCIDR to use (should match the kubernetes podCIDR)\n    #calicoNetworkCIDR: \"192.168.0.0/16\"\n\n    # Should be one of CALICO_IPV4POOL_IPIP or CALICO_IPV4POOL_VXLAN\n    encapsulationType: \"CALICO_IPV4POOL_IPIP\"\n\n    # Should be one of Always, CrossSubnet, Never\n    encapsulationMode: \"Always\"\n"
              },
              {
                "name": "kubernetes",
                "tag": "1.18.x",
                "uid": "6007ce6c861f9c0915b07611",
                "values": "pack:\n  k8sHardening: True\n  #CIDR Range for Pods in cluster\n  # Note : This must not overlap with any of the host or service network\n  podCIDR: \"192.168.0.0/16\"\n  #CIDR notation IP range from which to assign service cluster IPs\n  # Note : This must not overlap with any IP ranges assigned to nodes for pods.\n  serviceClusterIpRange: \"10.96.0.0/12\"\n\n# KubeAdm customization for kubernetes hardening. Below config will be ignored if k8sHardening property above is disabled\nkubeadmconfig:\n  apiServer:\n    extraArgs:\n      anonymous-auth: \"true\"\n      insecure-port: \"0\"\n      profiling: \"false\"\n      disable-admission-plugins: \"AlwaysAdmit\"\n      default-not-ready-toleration-seconds: \"60\"\n      default-unreachable-toleration-seconds: \"60\"\n      enable-admission-plugins: \"AlwaysPullImages,NamespaceLifecycle,ServiceAccount,NodeRestriction,PodSecurityPolicy\"\n      audit-log-path: /var/log/apiserver/audit.log\n      audit-policy-file: /etc/kubernetes/audit-policy.yaml\n      audit-log-maxage: \"30\"\n      audit-log-maxbackup: \"10\"\n      audit-log-maxsize: \"100\"\n      authorization-mode: RBAC,Node\n      tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n    extraVolumes:\n      - name: audit-log\n        hostPath: /var/log/apiserver\n        mountPath: /var/log/apiserver\n        pathType: DirectoryOrCreate\n      - name: audit-policy\n        hostPath: /etc/kubernetes/audit-policy.yaml\n        mountPath: /etc/kubernetes/audit-policy.yaml\n        readOnly: true\n        pathType: File\n  controllerManager:\n    extraArgs:\n      profiling: \"false\"\n      terminated-pod-gc-threshold: \"25\"\n      pod-eviction-timeout: \"1m0s\"\n      use-service-account-credentials: \"true\"\n      feature-gates: \"RotateKubeletServerCertificate=true\"\n      address: \"0.0.0.0\"\n  scheduler:\n    extraArgs:\n      profiling: \"false\"\n      address: \"0.0.0.0\"\n  kubeletExtraArgs:\n    read-only-port : \"0\"\n    event-qps: \"0\"\n    feature-gates: \"RotateKubeletServerCertificate=true\"\n    protect-kernel-defaults: \"true\"\n    tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n  files:\n    - path: hardening/audit-policy.yaml\n      targetPath: /etc/kubernetes/audit-policy.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/privileged-psp.yaml\n      targetPath: /etc/kubernetes/hardening/privileged-psp.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/90-kubelet.conf\n      targetPath: /etc/sysctl.d/90-kubelet.conf\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n  preKubeadmCommands:\n    # For enabling 'protect-kernel-defaults' flag to kubelet, kernel parameters changes are required\n    - 'echo \"====\u003e Applying kernel parameters for Kubelet\"'\n    - 'sysctl -p /etc/sysctl.d/90-kubelet.conf'\n  postKubeadmCommands:\n    # Apply the privileged PodSecurityPolicy on the first master node ; Otherwise, CNI (and other) pods won't come up\n    - 'export KUBECONFIG=/etc/kubernetes/admin.conf'\n    # Sometimes api server takes a little longer to respond. Retry if applying the pod-security-policy manifest fails\n    - '[ -f \"$KUBECONFIG\" ] \u0026\u0026 { echo \" ====\u003e Applying PodSecurityPolicy\" ; until $(kubectl apply -f /etc/kubernetes/hardening/privileged-psp.yaml \u003e /dev/null ); do echo \"Failed to apply PodSecurityPolicies, will retry in 5s\" ; sleep 5 ; done ; } || echo \"Skipping PodSecurityPolicy for worker nodes\"'"
              },
              {
                "name": "ubuntu-vsphere",
                "tag": "LTS__18.4.x",
                "uid": "6007ce6c861f9c09b0f28da4",
                "values": "\n# Spectro Golden images includes most of the hardening standards recommended by CIS benchmarking v1.5\n\n# Uncomment below section to\n# 1. Include custom files to be copied over to the nodes and/or\n# 2. Execute list of commands before or after kubeadm init/join is executed\n#\n#kubeadmconfig:\n#  preKubeadmCommands:\n#  - echo \"Executing pre kube admin config commands\"\n#  - update-ca-certificates\n#  - 'systemctl restart containerd; sleep 3'\n#  - 'while [ ! -S /var/run/containerd/containerd.sock ]; do echo \"Waiting for containerd...\"; sleep 1; done'\n#  postKubeadmCommands:\n#  - echo \"Executing post kube admin config commands\"\n#  files:\n#  - targetPath: /usr/local/share/ca-certificates/mycom.crt\n#    targetOwner: \"root:root\"\n#    targetPermissions: \"0644\"\n#    content: |\n#      -----BEGIN CERTIFICATE-----\n#      MIICyzCCAbOgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl\n#      cm5ldGVzMB4XDTIwMDkyMjIzNDMyM1oXDTMwMDkyMDIzNDgyM1owFTETMBEGA1UE\n#      AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMdA\n#      nZYs1el/6f9PgV/aO9mzy7MvqaZoFnqO7Qi4LZfYzixLYmMUzi+h8/RLPFIoYLiz\n#      qiDn+P8c9I1uxB6UqGrBt7dkXfjrUZPs0JXEOX9U/6GFXL5C+n3AUlAxNCS5jobN\n#      fbLt7DH3WoT6tLcQefTta2K+9S7zJKcIgLmBlPNDijwcQsbenSwDSlSLkGz8v6N2\n#      7SEYNCV542lbYwn42kbcEq2pzzAaCqa5uEPsR9y+uzUiJpv5tDHUdjbFT8tme3vL\n#      9EdCPODkqtMJtCvz0hqd5SxkfeC2L+ypaiHIxbwbWe7GtliROvz9bClIeGY7gFBK\n#      jZqpLdbBVjo0NZBTJFUCAwEAAaMmMCQwDgYDVR0PAQH/BAQDAgKkMBIGA1UdEwEB\n#      /wQIMAYBAf8CAQAwDQYJKoZIhvcNAQELBQADggEBADIKoE0P+aVJGV9LWGLiOhki\n#      HFv/vPPAQ2MPk02rLjWzCaNrXD7aPPgT/1uDMYMHD36u8rYyf4qPtB8S5REWBM/Y\n#      g8uhnpa/tGsaqO8LOFj6zsInKrsXSbE6YMY6+A8qvv5lPWpJfrcCVEo2zOj7WGoJ\n#      ixi4B3fFNI+wih8/+p4xW+n3fvgqVYHJ3zo8aRLXbXwztp00lXurXUyR8EZxyR+6\n#      b+IDLmHPEGsY9KOZ9VLLPcPhx5FR9njFyXvDKmjUMJJgUpRkmsuU1mCFC+OHhj56\n#      IkLaSJf6z/p2a3YjTxvHNCqFMLbJ2FvJwYCRzsoT2wm2oulnUAMWPI10vdVM+Nc=\n#      -----END CERTIFICATE-----"
              }
            ],
            "timeouts": null,
            "type": "cluster"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoyMDAwMDAwMDAwMCwiZGVsZXRlIjoyMDAwMDAwMDAwMCwidXBkYXRlIjoyMDAwMDAwMDAwMH19",
          "dependencies": [
            "data.spectrocloud_pack.cni-vsphere",
            "data.spectrocloud_pack.csi-vsphere",
            "data.spectrocloud_pack.k8s-vsphere",
            "data.spectrocloud_pack.lbmetal-vsphere",
            "data.spectrocloud_pack.nginx-vsphere",
            "data.spectrocloud_pack.ubuntu-vsphere"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "spectrocloud_cluster_profile",
      "name": "prodvmware",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "cloud": "vsphere",
            "description": "basic cp",
            "id": "6011e0581d2aa08149c4f1b8",
            "name": "ProdVMware",
            "pack": [
              {
                "name": "lb-metallb",
                "tag": "0.8.x",
                "uid": "6007ce6c861f9c09408ed39e",
                "values": "manifests:\n  metallb:\n\n    #The namespace to use for deploying MetalLB\n    namespace: \"metallb-system\"\n\n    #MetalLB will skip setting .0 \u0026 .255 IP address when this flag is enabled\n    avoidBuggyIps: true\n\n    # Layer 2 config; The IP address range MetalLB should use while assigning IP's for svc type LoadBalancer\n    # For the supported formats, check https://metallb.universe.tf/configuration/#layer-2-configuration\n    addresses:\n    - 10.10.182.0-10.10.182.9\n"
              },
              {
                "name": "sapp-hipster",
                "tag": "2.0.x",
                "uid": "6007ce6c861f9c09662d7d5f",
                "values": "manifests:\n  hipster:\n    # Liveness probe default itmeout\n    timeout: 60\n\n    # Disable Tracing\n    disableTracing: true\n\n    # The namespace to create the app in\n    namespace: \"hipster-app\"\n\n"
              },
              {
                "name": "istio",
                "tag": "1.6.x",
                "uid": "6007ce6c861f9c08f704634d",
                "values": "charts:\n  istio-operator:\n    hub: docker.io/istio\n    tag: 1.6.2\n    operatorNamespace: istio-operator\n    istioNamespace: istio-system\n  istio-controlplane:\n    namespace: istio-system\n    controlPlaneName: istio-controlplane\n    ############################################ ISTIO PROFILES #################################################\n    # default: generally for production (istiod, prometheus, ingress gateway)\n    # demo: enable everything for production (istiod, prometheus, ingress gateway, egress, kiali, tracing)\n    # remote: remote cluster of a multicluster mesh, with a shared control plane\n    ############################################################################################################\n    spec:\n      profile: demo\n      # Disable Pod disruption budget for the additional components. Otherwise, pods will get stuck when node is drained\n      values:\n        kiali:\n          service:\n            type: LoadBalancer\n        global:\n          defaultPodDisruptionBudget:\n            enabled: false\n"
              },
              {
                "name": "csi-vsphere-volume",
                "tag": "1.0.x",
                "uid": "6007ce6c861f9c08ca138776",
                "values": "manifests:\n  vsphere:\n\n    #DiskFormat types : thin, zeroedthick and eagerzeroedthick\n    diskformat: \"thin\"\n\n    #If specified, the volume will be created on the datastore specified in the storage class.\n    #This field is optional. If the datastore is not specified, then the volume will be created\n    # on the datastore specified in the vSphere config file used to initialize the vSphere Cloud Provider.\n    datastore: \"\"\n\n    #Toggle for Default class\n    isDefaultClass: \"true\"\n\n    #Supported binding modes are Immediate, WaitForFirstConsumer\n    volumeBindingMode: \"Immediate\""
              },
              {
                "name": "cni-calico",
                "tag": "3.16.x",
                "uid": "6007ce6c861f9c08697feca1",
                "values": "manifests:\n  calico:\n\n    # IPAM type to use. Supported types are calico-ipam, host-local\n    ipamType: \"host-local\"\n\n    # Uncomment property below when ipamType is set to calico-ipam\n    # networkCIDR to use (should match the kubernetes podCIDR)\n    #calicoNetworkCIDR: \"192.168.0.0/16\"\n\n    # Should be one of CALICO_IPV4POOL_IPIP or CALICO_IPV4POOL_VXLAN\n    encapsulationType: \"CALICO_IPV4POOL_IPIP\"\n\n    # Should be one of Always, CrossSubnet, Never\n    encapsulationMode: \"Always\"\n"
              },
              {
                "name": "kubernetes",
                "tag": "1.18.x",
                "uid": "6007ce6c861f9c0915b07611",
                "values": "pack:\n  k8sHardening: True\n  #CIDR Range for Pods in cluster\n  # Note : This must not overlap with any of the host or service network\n  podCIDR: \"192.168.0.0/16\"\n  #CIDR notation IP range from which to assign service cluster IPs\n  # Note : This must not overlap with any IP ranges assigned to nodes for pods.\n  serviceClusterIpRange: \"10.96.0.0/12\"\n\n# KubeAdm customization for kubernetes hardening. Below config will be ignored if k8sHardening property above is disabled\nkubeadmconfig:\n  apiServer:\n    extraArgs:\n      anonymous-auth: \"true\"\n      insecure-port: \"0\"\n      profiling: \"false\"\n      disable-admission-plugins: \"AlwaysAdmit\"\n      default-not-ready-toleration-seconds: \"60\"\n      default-unreachable-toleration-seconds: \"60\"\n      enable-admission-plugins: \"AlwaysPullImages,NamespaceLifecycle,ServiceAccount,NodeRestriction,PodSecurityPolicy\"\n      audit-log-path: /var/log/apiserver/audit.log\n      audit-policy-file: /etc/kubernetes/audit-policy.yaml\n      audit-log-maxage: \"30\"\n      audit-log-maxbackup: \"10\"\n      audit-log-maxsize: \"100\"\n      authorization-mode: RBAC,Node\n      tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n    extraVolumes:\n      - name: audit-log\n        hostPath: /var/log/apiserver\n        mountPath: /var/log/apiserver\n        pathType: DirectoryOrCreate\n      - name: audit-policy\n        hostPath: /etc/kubernetes/audit-policy.yaml\n        mountPath: /etc/kubernetes/audit-policy.yaml\n        readOnly: true\n        pathType: File\n  controllerManager:\n    extraArgs:\n      profiling: \"false\"\n      terminated-pod-gc-threshold: \"25\"\n      pod-eviction-timeout: \"1m0s\"\n      use-service-account-credentials: \"true\"\n      feature-gates: \"RotateKubeletServerCertificate=true\"\n      address: \"0.0.0.0\"\n  scheduler:\n    extraArgs:\n      profiling: \"false\"\n      address: \"0.0.0.0\"\n  kubeletExtraArgs:\n    read-only-port : \"0\"\n    event-qps: \"0\"\n    feature-gates: \"RotateKubeletServerCertificate=true\"\n    protect-kernel-defaults: \"true\"\n    tls-cipher-suites: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\"\n  files:\n    - path: hardening/audit-policy.yaml\n      targetPath: /etc/kubernetes/audit-policy.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/privileged-psp.yaml\n      targetPath: /etc/kubernetes/hardening/privileged-psp.yaml\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n    - path: hardening/90-kubelet.conf\n      targetPath: /etc/sysctl.d/90-kubelet.conf\n      targetOwner: \"root:root\"\n      targetPermissions: \"0600\"\n  preKubeadmCommands:\n    # For enabling 'protect-kernel-defaults' flag to kubelet, kernel parameters changes are required\n    - 'echo \"====\u003e Applying kernel parameters for Kubelet\"'\n    - 'sysctl -p /etc/sysctl.d/90-kubelet.conf'\n  postKubeadmCommands:\n    # Apply the privileged PodSecurityPolicy on the first master node ; Otherwise, CNI (and other) pods won't come up\n    - 'export KUBECONFIG=/etc/kubernetes/admin.conf'\n    # Sometimes api server takes a little longer to respond. Retry if applying the pod-security-policy manifest fails\n    - '[ -f \"$KUBECONFIG\" ] \u0026\u0026 { echo \" ====\u003e Applying PodSecurityPolicy\" ; until $(kubectl apply -f /etc/kubernetes/hardening/privileged-psp.yaml \u003e /dev/null ); do echo \"Failed to apply PodSecurityPolicies, will retry in 5s\" ; sleep 5 ; done ; } || echo \"Skipping PodSecurityPolicy for worker nodes\"'"
              },
              {
                "name": "ubuntu-vsphere",
                "tag": "LTS__18.4.x",
                "uid": "6007ce6c861f9c09b0f28da4",
                "values": "\n# Spectro Golden images includes most of the hardening standards recommended by CIS benchmarking v1.5\n\n# Uncomment below section to\n# 1. Include custom files to be copied over to the nodes and/or\n# 2. Execute list of commands before or after kubeadm init/join is executed\n#\n#kubeadmconfig:\n#  preKubeadmCommands:\n#  - echo \"Executing pre kube admin config commands\"\n#  - update-ca-certificates\n#  - 'systemctl restart containerd; sleep 3'\n#  - 'while [ ! -S /var/run/containerd/containerd.sock ]; do echo \"Waiting for containerd...\"; sleep 1; done'\n#  postKubeadmCommands:\n#  - echo \"Executing post kube admin config commands\"\n#  files:\n#  - targetPath: /usr/local/share/ca-certificates/mycom.crt\n#    targetOwner: \"root:root\"\n#    targetPermissions: \"0644\"\n#    content: |\n#      -----BEGIN CERTIFICATE-----\n#      MIICyzCCAbOgAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl\n#      cm5ldGVzMB4XDTIwMDkyMjIzNDMyM1oXDTMwMDkyMDIzNDgyM1owFTETMBEGA1UE\n#      AxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMdA\n#      nZYs1el/6f9PgV/aO9mzy7MvqaZoFnqO7Qi4LZfYzixLYmMUzi+h8/RLPFIoYLiz\n#      qiDn+P8c9I1uxB6UqGrBt7dkXfjrUZPs0JXEOX9U/6GFXL5C+n3AUlAxNCS5jobN\n#      fbLt7DH3WoT6tLcQefTta2K+9S7zJKcIgLmBlPNDijwcQsbenSwDSlSLkGz8v6N2\n#      7SEYNCV542lbYwn42kbcEq2pzzAaCqa5uEPsR9y+uzUiJpv5tDHUdjbFT8tme3vL\n#      9EdCPODkqtMJtCvz0hqd5SxkfeC2L+ypaiHIxbwbWe7GtliROvz9bClIeGY7gFBK\n#      jZqpLdbBVjo0NZBTJFUCAwEAAaMmMCQwDgYDVR0PAQH/BAQDAgKkMBIGA1UdEwEB\n#      /wQIMAYBAf8CAQAwDQYJKoZIhvcNAQELBQADggEBADIKoE0P+aVJGV9LWGLiOhki\n#      HFv/vPPAQ2MPk02rLjWzCaNrXD7aPPgT/1uDMYMHD36u8rYyf4qPtB8S5REWBM/Y\n#      g8uhnpa/tGsaqO8LOFj6zsInKrsXSbE6YMY6+A8qvv5lPWpJfrcCVEo2zOj7WGoJ\n#      ixi4B3fFNI+wih8/+p4xW+n3fvgqVYHJ3zo8aRLXbXwztp00lXurXUyR8EZxyR+6\n#      b+IDLmHPEGsY9KOZ9VLLPcPhx5FR9njFyXvDKmjUMJJgUpRkmsuU1mCFC+OHhj56\n#      IkLaSJf6z/p2a3YjTxvHNCqFMLbJ2FvJwYCRzsoT2wm2oulnUAMWPI10vdVM+Nc=\n#      -----END CERTIFICATE-----"
              }
            ],
            "timeouts": null,
            "type": "cluster"
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjoyMDAwMDAwMDAwMCwiZGVsZXRlIjoyMDAwMDAwMDAwMCwidXBkYXRlIjoyMDAwMDAwMDAwMH19",
          "dependencies": [
            "data.spectrocloud_pack.cni-vsphere",
            "data.spectrocloud_pack.csi-vsphere",
            "data.spectrocloud_pack.hipster-vsphere",
            "data.spectrocloud_pack.istio-vsphere",
            "data.spectrocloud_pack.k8s-vsphere",
            "data.spectrocloud_pack.lbmetal-vsphere",
            "data.spectrocloud_pack.ubuntu-vsphere"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "spectrocloud_cluster_vsphere",
      "name": "comp-3",
      "provider": "provider[\"registry.terraform.io/spectrocloud/spectrocloud\"]",
      "instances": [
        {
          "status": "tainted",
          "schema_version": 0,
          "attributes": {
            "cloud_account_id": "6011e1218102177b6b5aa9bd",
            "cloud_config": [
              {
                "datacenter": "Datacenter",
                "folder": "Demo/spc-vmware-discovery-1",
                "network_search_domain": "",
                "network_type": "",
                "ssh_key": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDAUaBODDNpQxJJqXz/Q+afauM5EPFp4oDRrWzK/cGd92N+exkd+tEZdO7n3R+WAx0XTcPiVvfKctzekNS6f/ZMrFb5HAPvFJtnGNIE2sm+eryEnAH+Sc7ppZha3/MaSp/A2dm2IobYRvwl04sEi4w1K+I8Rtt+fBe3gV3wnP3E3yOiRx4G2XFC3T6x8MjdOkjO2v6fBluw1M1H2etp1m/n4D70UkeyVJyipcntz0ubHweU7yPNdNS3YkpExYIGhm97C4dyESHEw9PZVdLs1FBL6mW5Yb4qVbg5FkLljLFynh9jL8IAYal0pibAAH+Sk/Nd4865lVJ3lrm8nhBnjs1OEFA487rcxyInxJk/WwLEHvo88Ku9IlYq15Alr8N/JHHackV4kAH0yJNeLtwAysK2gI7Mb5uGnMTPrz73IZqXSxFqnU34Ow+vwu8fXBtXmHA5cUHyz0ARzpgx8A0e8L8SjdY/6dsFhSzGo7JoCElN7sEMo7iI4Wdo8CYdlT+OXizBf3pnM/wxRZclCeRDJpLtd6jl5swv7J5ocINEh1r3BllCyV8L7Xp5gw8IKT3ohz6rliGJwwlq/emqY52eB3wweTLRm30z3h3aQa3YeAR+2JgvWlrJ3YWsYYCLRhSQTfYmpgUkoZIcfB2xkZzp6cyooM0i5Obz313HsxwBHOmNrw== spectro@spectro\n",
                "static_ip": true
              }
            ],
            "cloud_config_id": null,
            "cluster_profile_id": "6011e056c6fdecdfd8d25af5",
            "id": "6011ec751d2aa0845845b0da",
            "kubeconfig": null,
            "machine_pool": [
              {
                "control_plane": true,
                "control_plane_as_worker": true,
                "count": 3,
                "instance_type": [
                  {
                    "cpu": 2,
                    "disk_size_gb": 61,
                    "memory_mb": 4096
                  }
                ],
                "name": "master-pool",
                "placement": [
                  {
                    "cluster": "cluster1",
                    "datastore": "datastore54",
                    "network": "VM Network 2",
                    "resource_pool": "",
                    "static_ip_pool_id": "6011e1061d2aa08171553081"
                  },
                  {
                    "cluster": "cluster22",
                    "datastore": "datastore55",
                    "network": "VM Network 2",
                    "resource_pool": "",
                    "static_ip_pool_id": "6011e1061d2aa08171553081"
                  },
                  {
                    "cluster": "cluster33",
                    "datastore": "datastore56",
                    "network": "VM Network 2",
                    "resource_pool": "",
                    "static_ip_pool_id": "6011e1061d2aa08171553081"
                  }
                ],
                "update_strategy": "RollingUpdateScaleOut"
              }
            ],
            "name": "vmware-discovery-2",
            "pack": [],
            "timeouts": null
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjozNjAwMDAwMDAwMDAwLCJkZWxldGUiOjM2MDAwMDAwMDAwMDAsInVwZGF0ZSI6MzYwMDAwMDAwMDAwMH19",
          "dependencies": [
            "data.spectrocloud_cloudaccount_vsphere.this",
            "spectrocloud_cluster_profile.devvmware"
          ]
        }
      ]
    }
  ]
}
